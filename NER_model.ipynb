{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Named Entity Recognition for Prozhito","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport random\nfrom collections import defaultdict, Counter\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:39:37.640945Z","iopub.execute_input":"2023-05-31T09:39:37.641352Z","iopub.status.idle":"2023-05-31T09:39:37.655238Z","shell.execute_reply.started":"2023-05-31T09:39:37.641323Z","shell.execute_reply":"2023-05-31T09:39:37.654435Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn \nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import Dataset, DataLoader \nfrom torch.optim import Adam\nfrom transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModelForPreTraining\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom datasets import Dataset, DatasetDict, load_metric\nimport torch.nn.functional as F\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:39:37.656778Z","iopub.execute_input":"2023-05-31T09:39:37.657143Z","iopub.status.idle":"2023-05-31T09:39:51.792112Z","shell.execute_reply.started":"2023-05-31T09:39:37.657113Z","shell.execute_reply":"2023-05-31T09:39:51.791193Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:09.627100Z","iopub.execute_input":"2023-05-31T09:40:09.627799Z","iopub.status.idle":"2023-05-31T09:40:09.632351Z","shell.execute_reply.started":"2023-05-31T09:40:09.627766Z","shell.execute_reply":"2023-05-31T09:40:09.631239Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"label_list = ['B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-FAC', 'I-FAC', 'B-CHAR', 'I-CHAR', 'O']\nMODEL_PATH = \"DeepPavlov/rubert-base-cased-sentence\"\n\nOUTPUT_DIR = '.'\nres = {}\ntokenizer = None ","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:10.076997Z","iopub.execute_input":"2023-05-31T09:40:10.077655Z","iopub.status.idle":"2023-05-31T09:40:10.083746Z","shell.execute_reply.started":"2023-05-31T09:40:10.077620Z","shell.execute_reply":"2023-05-31T09:40:10.082849Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def set_random_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:11.103970Z","iopub.execute_input":"2023-05-31T09:40:11.104742Z","iopub.status.idle":"2023-05-31T09:40:11.111078Z","shell.execute_reply.started":"2023-05-31T09:40:11.104707Z","shell.execute_reply":"2023-05-31T09:40:11.109967Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"set_random_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:11.830945Z","iopub.execute_input":"2023-05-31T09:40:11.831317Z","iopub.status.idle":"2023-05-31T09:40:11.840749Z","shell.execute_reply.started":"2023-05-31T09:40:11.831289Z","shell.execute_reply":"2023-05-31T09:40:11.839859Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Uploading the Data","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/tatnashev/prozhito","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:12.805768Z","iopub.execute_input":"2023-05-31T09:40:12.806116Z","iopub.status.idle":"2023-05-31T09:40:15.205366Z","shell.execute_reply.started":"2023-05-31T09:40:12.806087Z","shell.execute_reply":"2023-05-31T09:40:15.204201Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Cloning into 'prozhito'...\nremote: Enumerating objects: 63, done.\u001b[K\nremote: Counting objects: 100% (63/63), done.\u001b[K\nremote: Compressing objects: 100% (37/37), done.\u001b[K\nremote: Total 63 (delta 32), reused 50 (delta 22), pack-reused 0\u001b[K\nUnpacking objects: 100% (63/63), 2.15 MiB | 4.75 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('prozhito/prozhito_data/df_train_prozhito.csv')\ndf_test = pd.read_csv('prozhito/prozhito_data/df_test_prozhito.csv')\ndf_val = pd.read_csv('prozhito/prozhito_data/df_val_prozhito.csv')\n\ndf_train['BIO_nums'] = df_train['BIO_nums'].apply(lambda x: eval(x))\ndf_test['BIO_nums'] = df_test['BIO_nums'].apply(lambda x: eval(x))\ndf_val['BIO_nums'] = df_val['BIO_nums'].apply(lambda x: eval(x))\n\ndf_train['BIO_list'] = df_train['BIO_list'].apply(lambda x: eval(x))\ndf_test['BIO_list'] = df_test['BIO_list'].apply(lambda x: eval(x))\ndf_val['BIO_list'] = df_val['BIO_list'].apply(lambda x: eval(x))\n\ndf_train['tokens'] = df_train['tokens'].apply(lambda x: x.split())\ndf_test['tokens'] = df_test['tokens'].apply(lambda x: x.split())\ndf_val['tokens'] = df_val['tokens'].apply(lambda x: x.split())\n\ndf_train = df_train[['tokens', 'BIO_list', 'BIO_nums']].rename(columns={'BIO_list': 'ner_bio', 'BIO_nums': 'ner_tags'})\ndf_test = df_test[['tokens', 'BIO_list', 'BIO_nums']].rename(columns={'BIO_list': 'ner_bio', 'BIO_nums': 'ner_tags'})\ndf_val = df_val[['tokens', 'BIO_list', 'BIO_nums']].rename(columns={'BIO_list': 'ner_bio', 'BIO_nums': 'ner_tags'})\n\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:15.207810Z","iopub.execute_input":"2023-05-31T09:40:15.209512Z","iopub.status.idle":"2023-05-31T09:40:15.366158Z","shell.execute_reply.started":"2023-05-31T09:40:15.209469Z","shell.execute_reply":"2023-05-31T09:40:15.365088Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 tokens  \\\n0     [У, меня, большая, симпатия, к, Лукьянину, —, ...   \n1     [>, Каким, приговором, ,, указом, каким, >, Ты...   \n2     [Подумал, ,, что, летом, ребята, куда, затащил...   \n3     [Нашел, потрясающие, материалы, о, В, ., М, .,...   \n4                                    [[Без, даты, ., ]]   \n...                                                 ...   \n1253  [Где, граница, между, сегодняшней, жизнью, и, ...   \n1254                      [Длится, уже, около, часа, .]   \n1255      [23, мая, ,, примерно, в, 7, часов, (, 18, .]   \n1256  [В, русском, переводе, примерно, такой, :, «, ...   \n1257  [Если, ,, как, это, у, них, принято, ,, письмо...   \n\n                                                ner_bio  \\\n0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n2                         [O, O, O, O, B-CHAR, O, O, O]   \n3     [O, O, O, O, B-PER, I-PER, I-PER, I-PER, I-PER...   \n4                                          [O, O, O, O]   \n...                                                 ...   \n1253                        [O, O, O, O, O, O, O, O, O]   \n1254                                    [O, O, O, O, O]   \n1255                     [O, O, O, O, O, O, O, O, O, O]   \n1256          [O, O, O, O, O, O, O, O, O, O, B-CHAR, O]   \n1257  [O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O,...   \n\n                                               ner_tags  \n0     [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  \n1     [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  \n2                       [10, 10, 10, 10, 8, 10, 10, 10]  \n3     [10, 10, 10, 10, 4, 5, 5, 5, 5, 10, 10, 8, 8, ...  \n4                                      [10, 10, 10, 10]  \n...                                                 ...  \n1253               [10, 10, 10, 10, 10, 10, 10, 10, 10]  \n1254                               [10, 10, 10, 10, 10]  \n1255           [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]  \n1256    [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10]  \n1257  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 2...  \n\n[1258 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_bio</th>\n      <th>ner_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[У, меня, большая, симпатия, к, Лукьянину, —, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[&gt;, Каким, приговором, ,, указом, каким, &gt;, Ты...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Подумал, ,, что, летом, ребята, куда, затащил...</td>\n      <td>[O, O, O, O, B-CHAR, O, O, O]</td>\n      <td>[10, 10, 10, 10, 8, 10, 10, 10]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Нашел, потрясающие, материалы, о, В, ., М, .,...</td>\n      <td>[O, O, O, O, B-PER, I-PER, I-PER, I-PER, I-PER...</td>\n      <td>[10, 10, 10, 10, 4, 5, 5, 5, 5, 10, 10, 8, 8, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[Без, даты, ., ]]</td>\n      <td>[O, O, O, O]</td>\n      <td>[10, 10, 10, 10]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1253</th>\n      <td>[Где, граница, между, сегодняшней, жизнью, и, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O]</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10]</td>\n    </tr>\n    <tr>\n      <th>1254</th>\n      <td>[Длится, уже, около, часа, .]</td>\n      <td>[O, O, O, O, O]</td>\n      <td>[10, 10, 10, 10, 10]</td>\n    </tr>\n    <tr>\n      <th>1255</th>\n      <td>[23, мая, ,, примерно, в, 7, часов, (, 18, .]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]</td>\n    </tr>\n    <tr>\n      <th>1256</th>\n      <td>[В, русском, переводе, примерно, такой, :, «, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, B-CHAR, O]</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10]</td>\n    </tr>\n    <tr>\n      <th>1257</th>\n      <td>[Если, ,, как, это, у, них, принято, ,, письмо...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O,...</td>\n      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 2...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1258 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets = DatasetDict({\n    'train': Dataset.from_pandas(df_train[['tokens', 'ner_tags']]),\n    'test': Dataset.from_pandas(df_test[['tokens', 'ner_tags']]),\n    'val': Dataset.from_pandas(df_val[['tokens', 'ner_tags']])\n})","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:15.368219Z","iopub.execute_input":"2023-05-31T09:40:15.368927Z","iopub.status.idle":"2023-05-31T09:40:15.401359Z","shell.execute_reply.started":"2023-05-31T09:40:15.368889Z","shell.execute_reply":"2023-05-31T09:40:15.400523Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets[\"train\"][2][\"ner_tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:15.404112Z","iopub.execute_input":"2023-05-31T09:40:15.404524Z","iopub.status.idle":"2023-05-31T09:40:15.411791Z","shell.execute_reply.started":"2023-05-31T09:40:15.404490Z","shell.execute_reply":"2023-05-31T09:40:15.410331Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[10, 10, 10, 10, 8, 10, 10, 10]\n","output_type":"stream"}]},{"cell_type":"code","source":"label_names = {\n    0: 'B-LOC',\n    1: 'I-LOC',\n    2: 'B-ORG',\n    3: 'I-ORG',\n    4: 'B-PER', \n    5: 'I-PER', \n    6: 'B-FAC',\n    7: 'I-FAC',\n    8: 'B-CHAR',\n    9: 'I-CHAR',\n    10: 'O'\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:15.413253Z","iopub.execute_input":"2023-05-31T09:40:15.413831Z","iopub.status.idle":"2023-05-31T09:40:15.421435Z","shell.execute_reply.started":"2023-05-31T09:40:15.413797Z","shell.execute_reply":"2023-05-31T09:40:15.420517Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"DeepPavlov/rubert-base-cased-sentence\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:15.422852Z","iopub.execute_input":"2023-05-31T09:40:15.423232Z","iopub.status.idle":"2023-05-31T09:40:17.190101Z","shell.execute_reply.started":"2023-05-31T09:40:15.423197Z","shell.execute_reply":"2023-05-31T09:40:17.189112Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14245ecaffc49a2a2ffb96782f6633d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c74b446c7e142b6a1e18dc39151fa58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ac2a57428c4784bd25d1f5511dc4d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f914163788fe41738fb50cd487e02ac7"}},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer(raw_datasets[\"train\"][2][\"tokens\"], is_split_into_words=True)\ninputs.tokens()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:17.191567Z","iopub.execute_input":"2023-05-31T09:40:17.192017Z","iopub.status.idle":"2023-05-31T09:40:17.208582Z","shell.execute_reply.started":"2023-05-31T09:40:17.191980Z","shell.execute_reply":"2023-05-31T09:40:17.207594Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'Под',\n '##ума',\n '##л',\n ',',\n 'что',\n 'летом',\n 'ребята',\n 'куда',\n 'зата',\n '##щил',\n '##и',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"inputs.word_ids()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:17.212454Z","iopub.execute_input":"2023-05-31T09:40:17.214351Z","iopub.status.idle":"2023-05-31T09:40:17.226497Z","shell.execute_reply.started":"2023-05-31T09:40:17.214316Z","shell.execute_reply":"2023-05-31T09:40:17.225580Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[None, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 7, None]"},"metadata":{}}]},{"cell_type":"code","source":"def align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:17.227830Z","iopub.execute_input":"2023-05-31T09:40:17.228613Z","iopub.status.idle":"2023-05-31T09:40:17.236708Z","shell.execute_reply.started":"2023-05-31T09:40:17.228580Z","shell.execute_reply":"2023-05-31T09:40:17.235963Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][2][\"ner_tags\"]\nword_ids = inputs.word_ids()\nprint(labels)\nprint(align_labels_with_tokens(labels, word_ids))","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:17.277510Z","iopub.execute_input":"2023-05-31T09:40:17.278228Z","iopub.status.idle":"2023-05-31T09:40:17.283869Z","shell.execute_reply.started":"2023-05-31T09:40:17.278197Z","shell.execute_reply":"2023-05-31T09:40:17.282936Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[10, 10, 10, 10, 8, 10, 10, 10]\n[-100, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, -100]\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:17.941510Z","iopub.execute_input":"2023-05-31T09:40:17.942211Z","iopub.status.idle":"2023-05-31T09:40:17.948168Z","shell.execute_reply.started":"2023-05-31T09:40:17.942153Z","shell.execute_reply":"2023-05-31T09:40:17.947110Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:18.351678Z","iopub.execute_input":"2023-05-31T09:40:18.352040Z","iopub.status.idle":"2023-05-31T09:40:18.713753Z","shell.execute_reply.started":"2023-05-31T09:40:18.352010Z","shell.execute_reply":"2023-05-31T09:40:18.712808Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2e6b9b8dd24779a7b803371d621d31"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db6218d812134aa8b87f1f5ac82d29f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373c96f57f47494598b0a566b25a6ef4"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:19.128617Z","iopub.execute_input":"2023-05-31T09:40:19.129493Z","iopub.status.idle":"2023-05-31T09:40:19.135736Z","shell.execute_reply.started":"2023-05-31T09:40:19.129448Z","shell.execute_reply":"2023-05-31T09:40:19.134794Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:20.032681Z","iopub.execute_input":"2023-05-31T09:40:20.033058Z","iopub.status.idle":"2023-05-31T09:40:35.071709Z","shell.execute_reply.started":"2023-05-31T09:40:20.033028Z","shell.execute_reply":"2023-05-31T09:40:35.070579Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.23.5)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.9.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=b24aca7a5d4e81d6a3e1ca47fba2db7040609b0f1c8cd7e34647740f535af75f\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:35.074096Z","iopub.execute_input":"2023-05-31T09:40:35.074502Z","iopub.status.idle":"2023-05-31T09:40:46.450521Z","shell.execute_reply.started":"2023-05-31T09:40:35.074463Z","shell.execute_reply":"2023-05-31T09:40:46.449330Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.4.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.28.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.64.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.13.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:46.453692Z","iopub.execute_input":"2023-05-31T09:40:46.454122Z","iopub.status.idle":"2023-05-31T09:40:47.249698Z","shell.execute_reply.started":"2023-05-31T09:40:46.454053Z","shell.execute_reply":"2023-05-31T09:40:47.248834Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea319a2b807042ed83bc700255d0a567"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:47.252436Z","iopub.execute_input":"2023-05-31T09:40:47.252817Z","iopub.status.idle":"2023-05-31T09:40:47.260524Z","shell.execute_reply.started":"2023-05-31T09:40:47.252781Z","shell.execute_reply":"2023-05-31T09:40:47.259526Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Defining a Model","metadata":{}},{"cell_type":"code","source":"id2label = {i: label for i, label in label_names.items()}\nlabel2id = {v: k for k, v in id2label.items()}","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:47.261874Z","iopub.execute_input":"2023-05-31T09:40:47.262682Z","iopub.status.idle":"2023-05-31T09:40:47.275049Z","shell.execute_reply.started":"2023-05-31T09:40:47.262648Z","shell.execute_reply":"2023-05-31T09:40:47.274032Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:47.276130Z","iopub.execute_input":"2023-05-31T09:40:47.276434Z","iopub.status.idle":"2023-05-31T09:40:52.494689Z","shell.execute_reply.started":"2023-05-31T09:40:47.276411Z","shell.execute_reply":"2023-05-31T09:40:52.493739Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded45f940f0d4037a46beffe23850485"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine-tuning the Model","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir='.',\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=20,\n    weight_decay=1e-4,\n    report_to='none',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    load_best_model_at_end=True,\n    save_total_limit=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:52.496356Z","iopub.execute_input":"2023-05-31T09:40:52.496737Z","iopub.status.idle":"2023-05-31T09:40:52.540225Z","shell.execute_reply.started":"2023-05-31T09:40:52.496686Z","shell.execute_reply":"2023-05-31T09:40:52.539505Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:40:52.543452Z","iopub.execute_input":"2023-05-31T09:40:52.544412Z","iopub.status.idle":"2023-05-31T09:46:57.994982Z","shell.execute_reply.started":"2023-05-31T09:40:52.544376Z","shell.execute_reply":"2023-05-31T09:46:57.993958Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3160' max='3160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3160/3160 05:58, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.105146</td>\n      <td>0.372549</td>\n      <td>0.542857</td>\n      <td>0.441860</td>\n      <td>0.957545</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.083998</td>\n      <td>0.589474</td>\n      <td>0.800000</td>\n      <td>0.678788</td>\n      <td>0.976004</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.067132</td>\n      <td>0.637363</td>\n      <td>0.828571</td>\n      <td>0.720497</td>\n      <td>0.980618</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.133500</td>\n      <td>0.070132</td>\n      <td>0.739726</td>\n      <td>0.771429</td>\n      <td>0.755245</td>\n      <td>0.986617</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.133500</td>\n      <td>0.053165</td>\n      <td>0.750000</td>\n      <td>0.814286</td>\n      <td>0.780822</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.133500</td>\n      <td>0.075026</td>\n      <td>0.820896</td>\n      <td>0.785714</td>\n      <td>0.802920</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.014300</td>\n      <td>0.069662</td>\n      <td>0.797297</td>\n      <td>0.842857</td>\n      <td>0.819444</td>\n      <td>0.987540</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.014300</td>\n      <td>0.069608</td>\n      <td>0.813333</td>\n      <td>0.871429</td>\n      <td>0.841379</td>\n      <td>0.989848</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.014300</td>\n      <td>0.073488</td>\n      <td>0.789474</td>\n      <td>0.857143</td>\n      <td>0.821918</td>\n      <td>0.987540</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.003500</td>\n      <td>0.071128</td>\n      <td>0.828571</td>\n      <td>0.828571</td>\n      <td>0.828571</td>\n      <td>0.989386</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.003500</td>\n      <td>0.070834</td>\n      <td>0.808219</td>\n      <td>0.842857</td>\n      <td>0.825175</td>\n      <td>0.989386</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.003500</td>\n      <td>0.076227</td>\n      <td>0.808219</td>\n      <td>0.842857</td>\n      <td>0.825175</td>\n      <td>0.989386</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.001200</td>\n      <td>0.074313</td>\n      <td>0.824324</td>\n      <td>0.871429</td>\n      <td>0.847222</td>\n      <td>0.990309</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.001200</td>\n      <td>0.075184</td>\n      <td>0.824324</td>\n      <td>0.871429</td>\n      <td>0.847222</td>\n      <td>0.990309</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001200</td>\n      <td>0.076418</td>\n      <td>0.802632</td>\n      <td>0.871429</td>\n      <td>0.835616</td>\n      <td>0.989848</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000800</td>\n      <td>0.079236</td>\n      <td>0.808219</td>\n      <td>0.842857</td>\n      <td>0.825175</td>\n      <td>0.988463</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000800</td>\n      <td>0.079644</td>\n      <td>0.808219</td>\n      <td>0.842857</td>\n      <td>0.825175</td>\n      <td>0.988463</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000800</td>\n      <td>0.078961</td>\n      <td>0.797297</td>\n      <td>0.842857</td>\n      <td>0.819444</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000500</td>\n      <td>0.080109</td>\n      <td>0.797297</td>\n      <td>0.842857</td>\n      <td>0.819444</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000500</td>\n      <td>0.080517</td>\n      <td>0.808219</td>\n      <td>0.842857</td>\n      <td>0.825175</td>\n      <td>0.988463</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3160, training_loss=0.024364790111733012, metrics={'train_runtime': 360.0386, 'train_samples_per_second': 69.881, 'train_steps_per_second': 8.777, 'total_flos': 525210426883176.0, 'train_loss': 0.024364790111733012, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T09:47:06.258964Z","iopub.execute_input":"2023-05-31T09:47:06.259380Z","iopub.status.idle":"2023-05-31T09:53:13.263844Z","shell.execute_reply.started":"2023-05-31T09:47:06.259348Z","shell.execute_reply":"2023-05-31T09:53:13.262832Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3160' max='3160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3160/3160 06:06, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.064448</td>\n      <td>0.780822</td>\n      <td>0.814286</td>\n      <td>0.797203</td>\n      <td>0.987079</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.080635</td>\n      <td>0.873016</td>\n      <td>0.785714</td>\n      <td>0.827068</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.060300</td>\n      <td>0.833333</td>\n      <td>0.857143</td>\n      <td>0.845070</td>\n      <td>0.990309</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.007300</td>\n      <td>0.063994</td>\n      <td>0.775000</td>\n      <td>0.885714</td>\n      <td>0.826667</td>\n      <td>0.989386</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.007300</td>\n      <td>0.071958</td>\n      <td>0.813333</td>\n      <td>0.871429</td>\n      <td>0.841379</td>\n      <td>0.989848</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.007300</td>\n      <td>0.072345</td>\n      <td>0.783784</td>\n      <td>0.828571</td>\n      <td>0.805556</td>\n      <td>0.988925</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.004400</td>\n      <td>0.064433</td>\n      <td>0.789474</td>\n      <td>0.857143</td>\n      <td>0.821918</td>\n      <td>0.989848</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.004400</td>\n      <td>0.074768</td>\n      <td>0.772152</td>\n      <td>0.871429</td>\n      <td>0.818792</td>\n      <td>0.989386</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.004400</td>\n      <td>0.082731</td>\n      <td>0.810811</td>\n      <td>0.857143</td>\n      <td>0.833333</td>\n      <td>0.988002</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.001400</td>\n      <td>0.067447</td>\n      <td>0.828571</td>\n      <td>0.828571</td>\n      <td>0.828571</td>\n      <td>0.990309</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.001400</td>\n      <td>0.084497</td>\n      <td>0.875000</td>\n      <td>0.800000</td>\n      <td>0.835821</td>\n      <td>0.988463</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.001400</td>\n      <td>0.067688</td>\n      <td>0.842857</td>\n      <td>0.842857</td>\n      <td>0.842857</td>\n      <td>0.991232</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000900</td>\n      <td>0.075494</td>\n      <td>0.867647</td>\n      <td>0.842857</td>\n      <td>0.855072</td>\n      <td>0.990771</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000900</td>\n      <td>0.075666</td>\n      <td>0.867647</td>\n      <td>0.842857</td>\n      <td>0.855072</td>\n      <td>0.990771</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000900</td>\n      <td>0.073122</td>\n      <td>0.855072</td>\n      <td>0.842857</td>\n      <td>0.848921</td>\n      <td>0.991232</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000400</td>\n      <td>0.077835</td>\n      <td>0.906250</td>\n      <td>0.828571</td>\n      <td>0.865672</td>\n      <td>0.990309</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000400</td>\n      <td>0.077758</td>\n      <td>0.892308</td>\n      <td>0.828571</td>\n      <td>0.859259</td>\n      <td>0.989848</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000400</td>\n      <td>0.073108</td>\n      <td>0.867647</td>\n      <td>0.842857</td>\n      <td>0.855072</td>\n      <td>0.990771</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000300</td>\n      <td>0.073710</td>\n      <td>0.867647</td>\n      <td>0.842857</td>\n      <td>0.855072</td>\n      <td>0.990771</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000300</td>\n      <td>0.073277</td>\n      <td>0.867647</td>\n      <td>0.842857</td>\n      <td>0.855072</td>\n      <td>0.990771</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3160, training_loss=0.0023265786810860605, metrics={'train_runtime': 363.6633, 'train_samples_per_second': 69.185, 'train_steps_per_second': 8.689, 'total_flos': 525210426883176.0, 'train_loss': 0.0023265786810860605, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/prozhito-texts/all_prozhito_texts_markup.csv')['text']\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batched(df, batch_size):\n    total = len(df)\n    n_steps = total // batch_size + (total % batch_size > 0)\n    for i in range(n_steps):\n        start = i * batch_size\n        stop = min((i + 1) * batch_size, total)\n        yield df.iloc[start:stop]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor batch in tqdm(batched(df, 128)):\n    batch_texts = batch.tolist()\n    batch_texts_lens = [len(t.split()) for t in batch_texts]\n    batch_encoded = {k: v.cuda() for k, v in tokenizer(batch_texts, return_tensors=\"pt\", padding=True).items()}\n    \n    batch_outputs = model(**batch_encoded)\n    batch_predictions = batch_outputs.logits.argmax(-1).detach().cpu().clone().numpy()\n    predictions.append(batch_predictions)\npredictions = np.concatenate(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = [\"Маша приехала в Москву и пошла в парк Горького\", 'Маша', 'я живу в России .']\ntexts_lens = [len(i.split()) for i in texts]\nencoding = {k: v.cuda() for k, v in tokenizer(text, return_tensors=\"pt\", padding=True).items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda()\noutputs = model(**encoding)\npredictions = outputs.logits.argmax(-1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = predictions.detach().cpu().clone().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess(predictions, label2id, texts_lens):\n    BIOs = []\n    for pred, text_len in zip(predictions, text\n                              s_lens):\n        bio = []\n        for label in pred[1:-1]:\n            bio.append(id2label[label])\n        BIOs.append(bio[:text_len])\n    return BIOs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"postprocess(predictions, label2id, texts_lens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}