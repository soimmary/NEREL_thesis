{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary for each type of relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_types = ['loc', 'per', 'fac', 'org', 'char']\n",
    "colours = {'loc': 'green', 'per': 'blue', 'fac': 'yellow', 'org': 'red', 'char': 'grey'}\n",
    "\n",
    "unselected = {\n",
    "    \"class\": \"text__unselected\",\n",
    "    # \"contentLength\": \n",
    "}\n",
    "\n",
    "pattern = {\n",
    "    \"class\": \"text__selected\", \n",
    "\n",
    "    \"textInputClasses\": \n",
    "    [\n",
    "        \"text__input\",\n",
    "        # \"text__input_{COLOUR}\"\n",
    "    ],\n",
    "    \n",
    "    \"tagSelectorClasses\": \n",
    "    [\n",
    "        \"text__selected-inner\",\n",
    "        # \"text__selected-inner_{COLOUR}\"\n",
    "    ],\n",
    "    \n",
    "    # \"value\": \"NER_TYPE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_template(pattern, ner_type):\n",
    "    templ = deepcopy(pattern)\n",
    "    templ['textInputClasses'].append(f\"text__input_{colours[ner_type]}\")\n",
    "    templ['tagSelectorClasses'].append(f\"text__selected-inner_{colours[ner_type]}\")\n",
    "    templ['value'] = ner_type\n",
    "    return templ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "- by NER tokens, their types and start positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(text: str, bio: str) -> (list, list, list):\n",
    "\n",
    "    text_split = text.split()\n",
    "    bio_split = bio.split()\n",
    "\n",
    "    left_context = 0\n",
    "    tokens = []\n",
    "    types = []\n",
    "    start_positions = []\n",
    "    phrase = ''\n",
    "    ner_type = ''\n",
    "\n",
    "    for i in range(len(text_split)):\n",
    "        token = text_split[i]\n",
    "        ner = bio_split[i]\n",
    "\n",
    "        if ner.startswith('B-') and phrase == '':\n",
    "            phrase = token\n",
    "            ner_type = ner\n",
    "\n",
    "            start_positions.append(left_context)\n",
    "            left_context += len(token) + 1\n",
    "\n",
    "        elif ner.startswith('B-') and phrase != '':\n",
    "            tokens.append(phrase)\n",
    "            types.append(ner_type[2:].lower())\n",
    "            phrase = token\n",
    "            ner_type = ner\n",
    "\n",
    "            start_positions.append(left_context)\n",
    "            left_context += len(token) + 1\n",
    "\n",
    "        elif ner.startswith('I-'):\n",
    "            phrase += ' ' + token\n",
    "            left_context += len(token) + 1\n",
    "\n",
    "        elif ner == 'O':\n",
    "            left_context += len(token) + 1\n",
    "\n",
    "    types.append(ner_type[2:].lower())\n",
    "    tokens.append(phrase)\n",
    "\n",
    "    return tokens, types, start_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 'result' markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result(tokens: list, types: list, start_positions: list) -> dict:\n",
    "    result_dict = {t: [] for t in types}\n",
    "\n",
    "    for token, t_type, start in zip(tokens, types, start_positions):\n",
    "        res = {\n",
    "            'position': start,\n",
    "            'value': token\n",
    "        }\n",
    "        result_dict[t_type].append(res)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 'text_review_mode' markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unselected(text: str, tokens: list, start_positions: list) -> list:\n",
    "    unselected_values = []\n",
    "    prev_sum = 0\n",
    "    \n",
    "    token_lens = [len(i) for i in tokens]\n",
    "    total_len = len(text)\n",
    "\n",
    "    unselected['contentLength'] = start_positions[0]\n",
    "    unselected_values.append(deepcopy(unselected))\n",
    "\n",
    "    for i in range(len(token_lens)):\n",
    "        start = start_positions[i]\n",
    "        length = token_lens[i]\n",
    "        prev_sum = start + length\n",
    "        try:\n",
    "            unselected['contentLength'] = start_positions[i+1] - prev_sum\n",
    "        except IndexError:\n",
    "            unselected['contentLength'] = total_len - prev_sum\n",
    "        unselected_values.append(deepcopy(unselected))\n",
    "        \n",
    "    return unselected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected(tokens: list, types: list, ner_templates: dict) -> list:\n",
    "    selected_result = []\n",
    "    token_lens = [len(i) for i in tokens]\n",
    "    \n",
    "    for token_len, ner_type in zip(token_lens, types):\n",
    "        \n",
    "        selected = deepcopy(ner_templates[ner_type])\n",
    "        selected['contentLength'] = token_len\n",
    "        selected_result.append(selected)\n",
    "    return selected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_review_mode(\n",
    "    text: str, \n",
    "    tokens: list, \n",
    "    types: list, \n",
    "    start_positions: list,\n",
    "    ner_templates: dict\n",
    ") -> list:\n",
    "    \n",
    "    selected_values = get_selected(tokens, types, ner_templates)\n",
    "    unselected_values = get_unselected(text, tokens, start_positions)\n",
    "    \n",
    "    for i, j in zip(\n",
    "        range(0, len(selected_values) * 2 + 1, 2), \n",
    "        range(len(unselected_values))\n",
    "    ):\n",
    "        selected_values.insert(i, unselected_values[j])\n",
    "    \n",
    "    return selected_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_js(text, bio, ner_templates):\n",
    "    \n",
    "    tokens, types, start_positions = split_data(text, bio)\n",
    "    result = create_result(tokens, types, start_positions)\n",
    "    text_review_mode = create_text_review_mode(text, tokens, types, start_positions, ner_templates)\n",
    "    \n",
    "    text_review_mode = str(text_review_mode)[1:-1].replace(\"'\", '\"')\n",
    "    result = str(result).replace(\"'\", '\"')\n",
    "    \n",
    "    return text, result, text_review_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_new.csv')[['tokens', 'BIO_str']]\n",
    "val_df = pd.read_csv('val_df_new.csv')[['tokens', 'BIO_str']]\n",
    "test_df = pd.read_csv('test_df_new.csv')[['tokens', 'BIO_str']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_templates = {\n",
    "    'loc': ner_template(pattern, 'loc'), \n",
    "    'per': ner_template(pattern, 'per'), \n",
    "    'org': ner_template(pattern, 'org'), \n",
    "    'char': ner_template(pattern, 'char'), \n",
    "    'fac': ner_template(pattern, 'fac')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_js = pd.DataFrame(columns=['INPUT:input', 'INPUT:result', 'INPUT:text_review_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test_df.iterrows():\n",
    "    text = row['tokens']\n",
    "    bio = row['BIO_str']\n",
    "    \n",
    "    if set(bio.split()) != {'O'}: # проверяем, что в строке есть ner'ы\n",
    "        text, result, text_review_mode = bio_to_js(text, bio, ner_templates)\n",
    "        df_js.loc[len(df_js.index)] = [text, result, text_review_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_js.to_csv('full_pool.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'В нем говорилось : > « Уважаемые Александр Сергеевич и Людмила Алексеевна !'\n",
    "bio = 'O O O O O O O B-PER I-PER O B-PER I-PER O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Александр Сергеевич', 'Людмила Алексеевна'], ['per', 'per'], [33, 55])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens, types, start_positions = split_data(text, bio)\n",
    "tokens, types, start_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_review_mode = create_text_review_mode(text, tokens, types, start_positions, ner_templates)    \n",
    "text_review_mode = str(text_review_mode)[1:-1].replace(\"'\", '\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('В нем говорилось : > « Уважаемые Александр Сергеевич и Людмила Алексеевна !',\n",
       " '{\"per\": [{\"position\": 33, \"value\": \"Александр Сергеевич\"}, {\"position\": 55, \"value\": \"Людмила Алексеевна\"}]}',\n",
       " '{\"class\": \"text__unselected\", \"contentLength\": 33}, {\"class\": \"text__selected\", \"textInputClasses\": [\"text__input\", \"text__input_blue\"], \"tagSelectorClasses\": [\"text__selected-inner\", \"text__selected-inner_blue\"], \"value\": \"per\", \"contentLength\": 19}, {\"class\": \"text__unselected\", \"contentLength\": 3}, {\"class\": \"text__selected\", \"textInputClasses\": [\"text__input\", \"text__input_blue\"], \"tagSelectorClasses\": [\"text__selected-inner\", \"text__selected-inner_blue\"], \"value\": \"per\", \"contentLength\": 18}, {\"class\": \"text__unselected\", \"contentLength\": 2}')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_to_js(text, bio, ner_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
